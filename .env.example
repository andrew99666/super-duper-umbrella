# Copy this file to .env and fill in the required secrets.
APP_SECRET_KEY=change-me
BASE_URL=http://localhost:8000
DATABASE_URL=sqlite:///./data/app.db

# Google Ads API credentials
GOOGLE_ADS_DEVELOPER_TOKEN=
GOOGLE_ADS_OAUTH_CLIENT_ID=
GOOGLE_ADS_OAUTH_CLIENT_SECRET=
# Optional: override the Google Ads API version (e.g. v21). Leave blank to use the library default.
GOOGLE_ADS_API_VERSION=
# Optional manager account login customer ID (without dashes)
GOOGLE_ADS_LOGIN_CUSTOMER_ID=

# OpenAI API key and prompt configuration
OPENAI_API_KEY=
OPENAI_MODEL=gpt-5-nano
OPENAI_PAGE_SUMMARY_SYSTEM_PROMPT="You analyze a landing page to infer its product/service, audience, and exclusions. Return a concise, factual summary (bulleted), avoid marketing fluff."
OPENAI_RELEVANCY_SYSTEM_PROMPT="Classify paid search queries for a given landing page and propose negatives. Definitions: - Relevant: clearly matches the offering and audience. - Irrelevant: clearly conflicts with the offering, audience, geo, prerequisites, or intent (e.g., jobs, support-only, DIY when service-only, out-of-area, competitors if LP doesn’t position against them, etc.). Negative keyword policy: - Prefer EXACT negatives for isolated one-off bad queries. - Use PHRASE negatives only when ≥3 irrelevant queries share the same non-brand phrase that safely removes a class of bad traffic. - PHRASE negatives must be 2–3 words, specific, and avoid overbroad tokens (e.g., not just “free”, “near me”). - Never generate negatives that block the brand/near-brand. - Keep all lowercase for negatives. Process (do silently; do NOT include reasoning in output): 1) For each query, decide Relevant vs Irrelevant using the LP summary’s “who it’s for” and “exclusions”.
2) Cluster irrelevant queries by shared 2–3-word phrases; promote a phrase to PHRASE negative if it appears in ≥3 queries and is non-brand, safe, and specific. Otherwise emit EXACT negatives for each irrelevant query. Output: - Output ONLY valid JSON matching the provided schema. - No extra text, comments, or Markdown."
# Optional: maximum concurrent OpenAI requests (default 60; we will use 85% of this value)
OPENAI_MAX_CONCURRENT_REQUESTS=
# Optional: number of search terms analysed per OpenAI request (default 80)
OPENAI_RELEVANCY_CHUNK_SIZE=
# Note: some OpenAI models (e.g. gpt-5-nano) enforce their default temperature. Overrides are ignored.
# Optional: cap on the number of search terms sent to the LLM per analysis run (default 1500)
OPENAI_MAX_TERMS=
# Optional: drop search terms with impressions below this threshold before LLM analysis (default 0)
OPENAI_MIN_IMPRESSIONS=

# Optional logging configuration
LOG_LEVEL=INFO

# Feature flags
FEATURE_APPLY_NEGATIVES=false
